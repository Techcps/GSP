{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f64a236-060b-4648-89fb-8ad86addde67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip3 install -q --upgrade pip\n",
    "!pip3 install -q google-cloud-aiplatform\n",
    "!pip3 install -q langchain\n",
    "!pip3 install -q langchain-community\n",
    "!pip3 install -q lxml\n",
    "!pip3 install -q requests\n",
    "!pip3 install -q beautifulsoup4\n",
    "!pip3 install -q unstructured\n",
    "!pip3 install -q langchain-google-genai\n",
    "!pip3 install -q google-generativeai\n",
    "!pip3 install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b371c287-5c4d-4f6d-9483-787ddb7a79c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernel\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac7c23-8831-4594-a9aa-a1aade9da542",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f13fb6-6a06-4dcb-9812-4643cb1f9cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d754a634-726f-4e04-bbec-ff241cfbdb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source API key from GCP project and configure genai client\n",
    "import os\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "key_name = !gcloud services api-keys list --filter=\"gemini-api-key\" --format=\"value(name)\"\n",
    "key_name = key_name[0]\n",
    "\n",
    "api_key = !gcloud services api-keys get-key-string $key_name --location=\"us-central1\" --format=\"value(keyString)\"\n",
    "api_key = api_key[0]\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db35058-5ee4-4eda-94d1-1c8fa96235fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project ID is: qwiklabs-gcp-00-4079a356a90c\n"
     ]
    }
   ],
   "source": [
    "# Define project information\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "PROJECT_ID = subprocess.check_output([\"gcloud\", \"config\", \"get-value\", \"project\"], text=True).strip()\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9781195e-7ab6-455b-9397-e166352bfb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set environment vars\n",
    "BUCKET = f\"gs://{PROJECT_ID}/embeddings\"\n",
    "DIMENSIONS=768\n",
    "DISPLAY_NAME='vertex_docs_qa'\n",
    "ENDPOINT=f\"{REGION}-aiplatform.googleapis.com\"\n",
    "TEXT_GENERATION_MODEL='gemini-pro'\n",
    "SITEMAP='https://docs.anthropic.com/sitemap.xml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15d201b-404b-4fbb-8ff2-7e45096ab2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f243a82-fb52-4874-a921-978a5a2769c4",
   "metadata": {},
   "source": [
    "# Task 1: Create Documents from Vertex AI Cloud Documentation Site\n",
    "\n",
    "## Load and parse sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6c90bd-1d13-4b5b-baaa-9d17b6097b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the xml of sitemap and get URLs of doc site\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_sitemap(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    urls = [element.text for element in soup.find_all(\"loc\")]\n",
    "    return urls\n",
    "\n",
    "sites = parse_sitemap(SITEMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a375b356-263c-481a-89eb-19eeacbf2088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this to filter out docs that don't have a corresponding reference page\n",
    "sites_filtered = [url for url in sites if '/en/docs' in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c956153-9c15-42b2-83fc-6c30c13d21c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sites_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc151f1f-0416-4421-909d-b792750220d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load documentation pages using the LangChain UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82632343-60bd-4c3c-a39d-ae728f75d1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This step will take a few minutes to complete\n",
    "# you will see download messages below the cell after execution\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "loader = UnstructuredURLLoader(urls=sites_filtered)\n",
    "documents = loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d537a9e4-85e1-44c8-9c91-fd32bc527566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Anthropic home page\n",
       "> \n",
       "> Talk to Claude\n",
       "> \n",
       "> Research\n",
       "> \n",
       "> News\n",
       "> \n",
       "> Talk to Claude\n",
       "> \n",
       "> Search\n",
       "> \n",
       "> Navigation\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Classification\n",
       "> \n",
       "> User Guides\n",
       "> \n",
       "> API Reference\n",
       "> \n",
       "> Prompt Library\n",
       "> \n",
       "> Release Notes\n",
       "> \n",
       "> Build with Claude Contest\n",
       "> \n",
       "> Developer Console\n",
       "> \n",
       "> Developer Discord\n",
       "> \n",
       "> Support\n",
       "> \n",
       "> Get started\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> Quickstart\n",
       "> \n",
       "> Intro to Claude\n",
       "> \n",
       "> Learn about Claude\n",
       "> \n",
       "> Use casesOverviewClassificationContent moderationTicket routing\n",
       "> \n",
       "> Models\n",
       "> \n",
       "> Security and compliance\n",
       "> \n",
       "> Build with Claude\n",
       "> \n",
       "> Define success criteria\n",
       "> \n",
       "> Develop test cases\n",
       "> \n",
       "> Prompt engineering\n",
       "> \n",
       "> Text generation\n",
       "> \n",
       "> Embeddings\n",
       "> \n",
       "> Google Sheets add-on\n",
       "> \n",
       "> Vision\n",
       "> \n",
       "> Tool use (function calling)\n",
       "> \n",
       "> Test and evaluate\n",
       "> \n",
       "> Strengthen guardrails\n",
       "> \n",
       "> Using the Evaluation Tool\n",
       "> \n",
       "> Resources\n",
       "> \n",
       "> Glossary\n",
       "> \n",
       "> System status\n",
       "> \n",
       "> Claude 3 model card\n",
       "> \n",
       "> Anthropic Cookbook\n",
       "> \n",
       "> Anthropic Courses\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Classification\n",
       "> \n",
       "> Claude excels at processing, understanding, and recognizing patterns in text, images, and data. These capabilities make Claude especially powerful for classification tasks.\n",
       "> \n",
       "> This guide walks through the process of determining the best approach for building a classifier with Claude and the essentials of end-to-end deployment for a Claude classifier, from use case exploration to back-end integration.\n",
       "> \n",
       "> Visit our \n",
       "> \n",
       "> classification cookbooks to see example classification implementations using Claude.\n",
       "> \n",
       "> ​When to use Claude for classification\n",
       "> \n",
       "> When should you consider using an LLM instead of a traditional ML approach for your classification tasks? Here are some key indicators:\n",
       "> \n",
       "> Rule-based classes: Use Claude when classes are defined by conditions rather than examples, as it can understand underlying rules.\n",
       "> \n",
       "> Evolving classes: Claude adapts well to new or changing domains with emerging classes and shifting boundaries.\n",
       "> \n",
       "> Unstructured inputs: Claude can handle large volumes of unstructured text inputs of varying lengths.\n",
       "> \n",
       "> Limited labeled examples: With few-shot learning capabilities, Claude learns accurately from limited labeled training data.\n",
       "> \n",
       "> Reasoning Requirements: Claude excels at classification tasks requiring semantic understanding, context, and higher-level reasoning.\n",
       "> \n",
       "> ​Establish your classification use case\n",
       "> \n",
       "> Below is a non-exhaustive list of common classification use cases where Claude excels by industry.\n",
       "> \n",
       "> Tech & IT\n",
       "> \n",
       "> Content moderation: automatically identify and flag inappropriate, offensive, or harmful content in user-generated text, images, or videos.\n",
       "> \n",
       "> Bug prioritization: calassify software bug reports based on their severity, impact, or complexity to prioritize development efforts and allocate resources effectively.\n",
       "> \n",
       "> Customer Service\n",
       "> \n",
       "> Intent analysis: determine what the user wants to achieve or what action they want the system to perform based on their text inputs.\n",
       "> \n",
       "> Support ticket routing: analyze customer interactions, such as call center transcripts or support tickets, to route issues to the appropriate teams, prioritize critical cases, and identify recurring problems for proactive resolution.\n",
       "> \n",
       "> Healthcare\n",
       "> \n",
       "> Patient triaging: classify customer intake conversations and data according to the urgency, topic, or required expertise for efficient triaging.\n",
       "> \n",
       "> Clinical trial screening: analyze patient data and medical records to identify and categorize eligible participants based on specified inclusion and exclusion criteria.\n",
       "> \n",
       "> Finance\n",
       "> \n",
       "> Fraud detection: identify suspicious patterns or anomalies in financial transactions, insurance claims, or user behavior to prevent and mitigate fraudulent activities.\n",
       "> \n",
       "> Credit risk assessment: classify loan applicants based on their creditworthiness into risk categories to automate credit decisions and optimize lending processes.\n",
       "> \n",
       "> Legal\n",
       "> \n",
       "> Legal document categorization: classify legal documents, such as pleadings, motions, briefs, or memoranda, based on their document type, purpose, or relevance to specific cases or clients.\n",
       "> \n",
       "> ​Implement Claude for classification\n",
       "> \n",
       "> The three key model decision factors are: intelligence, latency, and price.\n",
       "> \n",
       "> For classification, a smaller model like Claude 3 Haiku is typically ideal due to its speed and efficiency. Though, for classification tasks where specialized knowledge or complex reasoning is required, Sonnet or Opus may be a better choice. Learn more about how Opus, Sonnet, and Haiku compare here.\n",
       "> \n",
       "> Use evaluations to gauge whether a Claude model is performing well enough to launch into production.\n",
       "> \n",
       "> ​1. Build a strong input prompt\n",
       "> \n",
       "> While Claude offers high-level baseline performance out of the box, a strong input prompt helps get the best results.\n",
       "> \n",
       "> For a generic classifier that you can adapt to your specific use case, copy the starter prompt below:\n",
       "> \n",
       "> Starter prompt\n",
       "> \n",
       "> We also provide a wide range of prompts to get you started in our prompt library, including prompts for a number of classification use cases, including:\n",
       "> \n",
       "> Sentiment AnalysisDetect the tone and sentiment behind tweets. Understand user emotions, opinions, and reactions in real-time.\n",
       "> \n",
       "> Customer Review ClassificationCategorize feedback into pre-specified tags. Streamline product insights and customer service responses.\n",
       "> \n",
       "> ​2. Develop your test cases\n",
       "> \n",
       "> To run your classification evaluation, you will need test cases to run it on. Take a look at our guide to developing test cases.\n",
       "> \n",
       "> ​3. Run your eval\n",
       "> \n",
       "> ​Evaluation metrics\n",
       "> \n",
       "> Some success metrics to consider evaluating Claude’s performance on a classification task include:\n",
       "> \n",
       "> Criteria Description Accuracy The model’s output exactly matches the golden answer or correctly classifies the input according to the task’s requirements. This is typically calculated as (Number of correct predictions) / (Overall number of predictions). F1 Score The model’s output optimally balances precision and recall. Consistency The model’s output is consistent with its predictions for similar inputs or follows a logical pattern. Structure The model’s output follows the expected format or structure, making it easy to parse and interpret. For example, many classifiers are expected to output JSON format. Speed The model provides a response within the acceptable time limit or latency threshold for the task. Bias and Fairness If classifying data about people, is it important that the model does not demonstrate any biases based on gender, ethnicity, or other characteristics that would lead to its misclassification.\n",
       "> \n",
       "> ​Deploy your classifier\n",
       "> \n",
       "> To see code examples of how to use Claude for classification, check out the Classification Guide in the Anthropic Cookbook.\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> Content moderation\n",
       "> \n",
       "> linkedin\n",
       "> \n",
       "> On this page\n",
       "> \n",
       "> When to use Claude for classification\n",
       "> \n",
       "> Establish your classification use case\n",
       "> \n",
       "> Implement Claude for classification\n",
       "> \n",
       "> 1. Build a strong input prompt\n",
       "> \n",
       "> 2. Develop your test cases\n",
       "> \n",
       "> 3. Run your eval\n",
       "> \n",
       "> Evaluation metrics\n",
       "> \n",
       "> Deploy your classifier\n",
       "> \n",
       "> Source: https://docs.anthropic.com/en/docs/about-claude/use-cases/classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(documents[1].page_content + \"\\n\\nSource: \" + documents[1].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacb3e49-cd62-4043-9440-5013eb1797b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f00b5-4022-467e-a001-008b8a53768c",
   "metadata": {},
   "source": [
    "## Create Document chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eccee30-c90b-4243-a445-53950364b3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number documents 33\n",
      "Number chunks 190\n"
     ]
    }
   ],
   "source": [
    "# recursively loop through the text and create document chunks for embedding\n",
    "import warnings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #separator = \"\\n\",\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 100)\n",
    "\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Number documents {len(documents)}\")\n",
    "print(f\"Number chunks {len(document_chunks)}\")\n",
    "\n",
    "document_chunks=[f\"content: {chunk.page_content}, source: {chunk.metadata['source']}\" for chunk in document_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7387e-11df-4d72-9fb0-dda3acc098d8",
   "metadata": {},
   "source": [
    "# Task 2: Generate embeddings from Document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b57362bd-7e38-445c-ada9-20e57132bbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a documents directory\n",
    "!rm -rf ./documents\n",
    "!mkdir ./documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc6e60a-aa97-4553-a50d-58649e84df60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content: Anthropic home page\\n\\nTalk to Claude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content: Model Anthropic API AWS Bedrock GCP V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content: ​Prompt and output performance\\n\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>content: Claude 2.1 Claude 2 Claude Instant 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content: Ticket routing\\n\\nSecurity and compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>content: Set appropriate output limits: Use th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>content: Anthropic home page\\n\\nTalk to Claude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>content: Example: Safeguarding proprietary ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>content: Anthropic home page\\n\\nTalk to Claude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>content: ​Key capabilities\\n\\nClaude can assis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    content: Anthropic home page\\n\\nTalk to Claude...\n",
       "1    content: Model Anthropic API AWS Bedrock GCP V...\n",
       "2    content: ​Prompt and output performance\\n\\nThe...\n",
       "3    content: Claude 2.1 Claude 2 Claude Instant 1....\n",
       "4    content: Ticket routing\\n\\nSecurity and compli...\n",
       "..                                                 ...\n",
       "185  content: Set appropriate output limits: Use th...\n",
       "186  content: Anthropic home page\\n\\nTalk to Claude...\n",
       "187  content: Example: Safeguarding proprietary ana...\n",
       "188  content: Anthropic home page\\n\\nTalk to Claude...\n",
       "189  content: ​Key capabilities\\n\\nClaude can assis...\n",
       "\n",
       "[190 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the document chunks in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(document_chunks, columns =['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba0a5ff-26a5-4023-b833-fb9f9b418a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:26<00:00,  7.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate the embeddings files you will later upload to Cloud Storage\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "index_embeddings = []\n",
    "model = \"models/embedding-001\"\n",
    "\n",
    "for index, doc in tqdm(df.iterrows(), total=len(df), position=0):\n",
    "\n",
    "    response = genai.embed_content(model=model, content=doc['text'], task_type=\"retrieval_query\")\n",
    "\n",
    "    doc_id=f\"{index}.txt\"\n",
    "    embedding_dict = {\n",
    "        \"id\": doc_id,\n",
    "        \"embedding\": response[\"embedding\"],\n",
    "    }\n",
    "    index_embeddings.append(json.dumps(embedding_dict) + \"\\n\")\n",
    "    \n",
    "    with open(f\"documents/{doc_id}\", \"w\") as document:\n",
    "          document.write(doc['text'])\n",
    "    \n",
    "with open(\"embeddings.json\", \"w\") as f:\n",
    "    f.writelines(index_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93913e92-4c3f-46cc-9498-cde46fe559f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "source_file = '/home/jupyter/embeddings.json'\n",
    "destination_blob_name = 'embeddings/embeddings.json' # Adjust if needed\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.bucket(PROJECT_ID)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa9c1278-41f3-4892-bd7d-a9d6eb7848c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gsutil', '-q', 'cp', '-r', './documents', 'gs://qwiklabs-gcp-00-4079a356a90c/documents'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the embedding files to Cloud Storage\n",
    "# This step will take a few minutes to complete\n",
    "import subprocess\n",
    "gsutil_command = f\"gsutil -q cp -r './documents' gs://{PROJECT_ID}/documents\"\n",
    "\n",
    "subprocess.run(['gsutil', '-q', 'cp', '-r', './documents', f'gs://{PROJECT_ID}/documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056208e-7570-4005-b274-90e62d539fb9",
   "metadata": {},
   "source": [
    "# Task 3. Create a Vertex AI Vector Store index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7566d26d-d5eb-4774-80a3-dc61b570fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/546645938624/locations/us-central1/indexes/4158805975039475712/operations/2653598505351774208\n",
      "MatchingEngineIndex created. Resource name: projects/546645938624/locations/us-central1/indexes/4158805975039475712\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/546645938624/locations/us-central1/indexes/4158805975039475712')\n"
     ]
    }
   ],
   "source": [
    "# Create the Vertex AI Vector Search index\n",
    "# This step will take several minutes to complete\n",
    "# Wait for this cell to complete before proceeding\n",
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "      display_name=\"vertex_docs\",\n",
    "      contents_delta_uri=f\"gs://{PROJECT_ID}/embeddings\",\n",
    "      dimensions=768,\n",
    "      approximate_neighbors_count=150,\n",
    "      distance_measure_type=\"DOT_PRODUCT_DISTANCE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ced8d73-3b98-4e55-89ca-a29bcb086d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784/operations/9013807079105757184\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784')\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"vertex_docs\",\n",
    "    description=\"Embeddings for the documentation curated from the sitemap.\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "089e1afb-4cfe-4dad-b8c4-e2c569861bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscribe to techcps\n"
     ]
    }
   ],
   "source": [
    "print(\"subscribe to techcps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b42d4077-275f-43cf-8c55-993e0880d651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784/operations/410805890921267200\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784\n"
     ]
    }
   ],
   "source": [
    "# This step will take up to 20 minutes to complete\n",
    "# You can view the deployment in the Vertex AI console on the \"Vector Search\" tab\n",
    "# Wait for this cell to complete before proceeding\n",
    "index_endpoint = index_endpoint.deploy_index(\n",
    "    index=index, deployed_index_id=\"vertex_index_deployment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "877608b4-9496-48c5-8513-799d6324f3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index_endpoint: \"projects/546645938624/locations/us-central1/indexEndpoints/2494444437749366784\"\n",
       "deployed_index_id: \"vertex_index_deployment\"\n",
       "]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME=index.resource_name\n",
    "index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)\n",
    "\n",
    "deployed_index = index.deployed_indexes\n",
    "deployed_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a81baa-a4f6-4712-8db2-339b3ca74e35",
   "metadata": {},
   "source": [
    "# Task 4: Search Vector Store, add result as context to a query (without using a LangChain Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f563bb-4417-4eac-b675-2377e151357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the next cells you will query the model directly using the Vertex AI python SDK\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores.matching_engine import MatchingEngine\n",
    "from langchain.agents import Tool\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "def search_vector_store(question):\n",
    "\n",
    "    vector_store = MatchingEngine.from_components(\n",
    "                        index_id=INDEX_RESOURCE_NAME,\n",
    "                        region=REGION,\n",
    "                        embedding=embeddings,\n",
    "                        project_id=PROJECT_ID,\n",
    "                        endpoint_id=deployed_index[0].index_endpoint,\n",
    "                        gcs_bucket_name=f\"{PROJECT_ID}\")\n",
    "    \n",
    "    relevant_documentation=vector_store.similarity_search(question, k=8)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_documentation])[:10000]\n",
    "    return str(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42442602-f577-4cb2-b4a9-e26fa2425cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "import warnings\n",
    "\n",
    "# filter warnings for unused libs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def ask_question(question):\n",
    "    context = search_vector_store(question)\n",
    "\n",
    "    prompt=f\"\"\"\n",
    "        Follow exactly those 3 steps:\n",
    "        1. Read the context below and aggregrate this data\n",
    "        Context : {context}\n",
    "        2. Answer the question using only this context\n",
    "        3. Show the source for your answers\n",
    "        User Question: {question}\n",
    "\n",
    "\n",
    "        If you don't have any context and are unsure of the answer, reply that you don't know about this topic.\n",
    "        \"\"\"\n",
    "\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    return to_markdown(f\"Question: \\n{question} \\n\\n Response: \\n {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61376c0e-0447-4527-b212-e65f6b128fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Question: \n",
       "> How do I reduce prompt leaks? \n",
       "> \n",
       ">  Response: \n",
       ">  ##  Summary of Anthropic's documentation on reducing prompt leaks in Claude\n",
       "> \n",
       "> **Prompt leaks** occur when sensitive information intended to be hidden in a prompt is exposed in the model's output. While completely eliminating this risk is difficult, Anthropic offers various strategies to significantly reduce it.\n",
       "> \n",
       "> **Here's a summary of their recommendations:**\n",
       "> \n",
       "> **Before you try to reduce prompt leak:**\n",
       "> \n",
       "> * Use leak-resistant techniques only when necessary, as they can negatively impact performance.\n",
       "> * Implement leak-resistant techniques only after testing your prompts thoroughly.\n",
       "> * Monitor outputs for potential leaks using tools like output screening or post-processing.\n",
       "> \n",
       "> **Strategies to reduce prompt leak:**\n",
       "> \n",
       "> * **Separate context from queries:** Use system prompts to isolate key information and context from user queries. \n",
       "> * **Use post-processing:** Filter Claude's outputs for keywords that might indicate a leak. Regular expressions, keyword filtering, and other text processing methods can be used for this.\n",
       "> * **Avoid unnecessary proprietary details:** Don't include information in the prompt that Claude doesn't need to perform the task.\n",
       "> * **Regular audits:** Periodically review your prompts and Claude's outputs for potential leaks.\n",
       "> \n",
       "> **Additional resources:**\n",
       "> \n",
       "> * Advanced: Chain safeguards: https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks\n",
       "> * Prompt engineering tutorial: https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\n",
       "> \n",
       "> \n",
       "> ## Answer to the user question: \"How do I reduce prompt leaks?\"\n",
       "> \n",
       "> Based on Anthropic's documentation, here are some ways to reduce prompt leaks:\n",
       "> \n",
       "> * **Separate context from queries:** Instead of including all relevant information in the user prompt, use system prompts to provide additional context and instructions.\n",
       "> * **Use post-processing:** Filter the model's output for keywords or patterns that might indicate a leak.\n",
       "> * **Avoid including unnecessary details:** Don't include information in the prompt that Claude doesn't need to complete the task.\n",
       "> * **Regularly audit your prompts and outputs:** Look for potential leaks in your prompts and the model's outputs, and refine your strategies as needed.\n",
       "> \n",
       "> Remember, reducing prompt leaks is an ongoing process. Regularly reviewing your prompts and outputs and using appropriate mitigation strategies will help you keep your data safe.\n",
       "> \n",
       "> ##  Source for my answer:\n",
       "> \n",
       "> * Anthropic documentation on prompt leaks: https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak\n",
       "> \n",
       "> \n",
       "> I hope this information is helpful!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"How do I reduce prompt leaks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edef10e5-28ab-49f1-bc35-a783ef03e572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Question: \n",
       "> What use cases and capabilities does Anthropic support? \n",
       "> \n",
       ">  Response: \n",
       ">  ## Answer based on aggregated data:\n",
       "> \n",
       "> **Use cases:**\n",
       "> \n",
       "> * **Text and code generation:** \n",
       ">     * summarize text, answer questions, extract data, translate text, \n",
       ">     * explain and generate code, \n",
       ">     * create production-level code and operate within complex codebases.\n",
       "> * **Vision:**\n",
       ">     * process and analyze visual input,\n",
       ">     * generate code from images with code snippets or templates based on diagrams,\n",
       ">     * describe an image for a user with low vision.\n",
       "> * **Tool use:**\n",
       ">     * interact with external client-side tools and functions,\n",
       ">     * reason, plan, and execute actions by generating structured outputs through API calls.\n",
       "> \n",
       "> **Capabilities:**\n",
       "> \n",
       "> * **Text generation:**\n",
       ">     * Adhere to brand voice for excellent customer-facing experiences such as copywriting and chatbots.\n",
       "> * **Code generation:**\n",
       ">     * Create production-level code and operate (in-line code generation, debugging, and conversational querying) within complex codebases.\n",
       "> * **Translation:**\n",
       ">     * Build automatic translation features between languages.\n",
       "> * **Financial forecasting:**\n",
       ">     * Conduct complex financial forecasts.\n",
       "> * **Legal analysis:**\n",
       ">     * Support legal use cases that require high-quality technical analysis, long context windows for processing detailed documents, and fast outputs.\n",
       "> * **Vision:**\n",
       ">     * Process and analyze visual input, such as extracting insights from charts and graphs.\n",
       "> * **Tool use:**\n",
       ">     * Interact with external client-side tools and functions, allowing Claude to reason, plan, and execute actions by generating structured outputs through API calls.\n",
       "> \n",
       "> **Sources:**\n",
       "> \n",
       "> * https://docs.anthropic.com/en/docs/intro-to-claude\n",
       "> * https://docs.anthropic.com/en/docs/welcome\n",
       "> \n",
       "> ---\n",
       "> \n",
       "> **Note:** This is just a summary of the information available in the context. For a more comprehensive understanding of Anthropic's use cases and capabilities, please refer to the source documents."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"What use cases and capabilities does Anthropic support?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730748e8-587d-4a07-b707-9f945e6ec96a",
   "metadata": {},
   "source": [
    "# Task 5: Create Retrieval Augmentation Generation application using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bf0e958-9d7b-44f0-8893-a508250fa836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To answer questions and chain together the prompt, vector search, returned context and model input use a LangChain \"Chain\"\n",
    "# In this case you will use the RetrievalQA chain which is commonly used for Question/Answering applications\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# initialize model using chat\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.0, convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e2d89b2-7cab-4b72-ab2c-c0c931c777ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Follow exactly those 3 steps:\n",
    "    1. Read the context below and aggregrate this data\n",
    "    Context : {context}\n",
    "    \n",
    "    2. Answer the question using only this context\n",
    "    3. Show the source for your answers\n",
    "    User Question: {question}\n",
    "\n",
    "    If you don't have any context and are unsure of the answer, reply that you don't know about this topic.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"context\",  \"question\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4576213f-c4f0-4603-9ffb-5f4692f425e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> content: Use Workbench to create evals, draft prompts, and iteratively refine based on test results.\n",
       "> \n",
       "> Deploy polished prompts and monitor real-world performance for further refinement.\n",
       "> \n",
       "> Implement Claude\n",
       "> \n",
       "> Set up your environment, integrate Claude with your systems (APIs, databases, UIs), and define human-in-the-loop requirements.\n",
       "> \n",
       "> Test your system\n",
       "> \n",
       "> Conduct red teaming for potential misuse and A/B test improvements.\n",
       "> \n",
       "> Deploy to production\n",
       "> \n",
       "> Once your application runs smoothly end-to-end, deploy to production.\n",
       "> \n",
       "> Monitor and improve\n",
       "> \n",
       "> Monitor performance and effectiveness to make ongoing improvements.\n",
       "> \n",
       "> ​Start building with Claude\n",
       "> \n",
       "> When you’re ready, start building with Claude:\n",
       "> \n",
       "> Follow the Quickstart to make your first API call\n",
       "> \n",
       "> Check out the API Reference\n",
       "> \n",
       "> Explore the Prompt Library for example prompts\n",
       "> \n",
       "> Experiment and start building with the Workbench\n",
       "> \n",
       "> Check out the Anthropic Cookbook for working code examples\n",
       "> \n",
       "> Quickstart\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> linkedin\n",
       "> \n",
       "> On this page\n",
       "> \n",
       "> What you can do with Claude\n",
       "> \n",
       "> Model options\n",
       "> \n",
       "> Claude 3.5 Family\n",
       "> \n",
       "> Claude 3 Family\n",
       "> \n",
       "> Enterprise considerations\n",
       "> \n",
       "> Implementing Claude\n",
       "> \n",
       "> Start building with Claude, source: https://docs.anthropic.com/en/docs/intro-to-claude"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores.matching_engine import MatchingEngine\n",
    "\n",
    "vector_store = MatchingEngine.from_components(\n",
    "    index_id=INDEX_RESOURCE_NAME,\n",
    "    region=REGION,\n",
    "    embedding=embeddings,\n",
    "    project_id=PROJECT_ID,\n",
    "    endpoint_id=deployed_index[0].index_endpoint,\n",
    "    gcs_bucket_name=f\"{PROJECT_ID}\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 1}\n",
    ")\n",
    "\n",
    "# Test the retriever with a simple search performed above\n",
    "to_markdown(retriever.get_relevant_documents(\"How do I get started with Anthropic?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4caa14bf-0cab-4955-8fb2-d44682c52756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b756d95c-fe7f-4eaa-b1c7-0fa6f3fb5187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_question(question: str):\n",
    "    response = qa({\"query\": question})\n",
    "\n",
    "    # since k is set to 1 only return the first source retrieved\n",
    "    source = response['source_documents']\n",
    "    \n",
    "    return to_markdown(f\"Response: \\n\\n {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b220d283-bf02-4a4b-9975-dc3d0a4c2b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Response: \n",
       "> \n",
       ">  1. Follow the Quickstart to make your first API call\n",
       "> 2. Check out the API Reference\n",
       "> 3. Explore the Prompt Library for example prompts\n",
       "> 4. Experiment and start building with the Workbench\n",
       "> 5. Check out the Anthropic Cookbook for working code examples\n",
       "> \n",
       "> Source: https://docs.anthropic.com/en/docs/intro-to-claude"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: You will see a library warning when running this step\n",
    "ask_question(\"How do I get started with Anthropic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83df31-6535-4902-a5bb-1fb225b82add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f774dc-305b-4287-a7c8-e3d4a9a707dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-16.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-16:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
