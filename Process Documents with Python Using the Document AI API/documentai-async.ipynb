{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0J138mj7p1s"
   },
   "source": [
    "# Document AI Asynchronous API\n",
    "This notebook shows you how use Python to make asynchronous calls to the Document AI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must replace the `processor_id` variable value in the the second cell with the appropriate value for the Processor ID of the Document AI processor that you want to use. The processor may not support all of the Document AI output properties. Entity data is only returned by processors that use specialized parsers for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8eO6Kcp7v2x"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Processor ID\n",
    "processor_id = \"PROCESSOR_ID\"  # TODO: Replace with a valid Processor ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3c1mTa6IOk3"
   },
   "outputs": [],
   "source": [
    "# Set your variables\n",
    "project_id = %system gcloud config get-value core/project\n",
    "project_id = project_id[0]\n",
    "location = 'us'           # Replace with 'eu' if processor does not use 'us' location\n",
    "gcs_input_bucket  = project_id+\"_doc_ai_async\"   # Bucket name only, no gs:// prefix\n",
    "gcs_input_prefix  = \"input/\"                     # Input bucket folder e.g. input/\n",
    "gcs_output_bucket = project_id+\"_doc_ai_async\"   # Bucket name only, no gs:// prefix\n",
    "gcs_output_prefix = \"output/\"                    # Input bucket folder e.g. output/\n",
    "timeout = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Google Cloud client objects\n",
    "client_options = {\"api_endpoint\": \"{}-documentai.googleapis.com\".format(location)}\n",
    "client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please like share and subscribe to Techcps\n",
    "# https://www.youtube.com/@techcps\n",
    "\n",
    "print(\"please like share and subscribe to techcps https://www.youtube.com/@techcps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input configuration\n",
    "blobs = storage_client.list_blobs(gcs_input_bucket, prefix=gcs_input_prefix)\n",
    "input_configs = []\n",
    "print(\"Input Files:\")\n",
    "for blob in blobs:\n",
    "    if \".pdf\" in blob.name:\n",
    "        source = \"gs://{bucket}/{name}\".format(bucket = gcs_input_bucket, name = blob.name)\n",
    "        print(source)\n",
    "        input_config = documentai.types.document_processor_service.BatchProcessRequest.BatchInputConfig(\n",
    "            gcs_source=source, mime_type=\"application/pdf\"\n",
    "        )\n",
    "        input_configs.append(input_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output configuration\n",
    "destination_uri = f\"gs://{gcs_output_bucket}/{gcs_output_prefix}\"\n",
    "output_config = documentai.types.document_processor_service.BatchProcessRequest.BatchOutputConfig(\n",
    "    gcs_destination=destination_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Document AI API request\n",
    "name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "request = documentai.types.document_processor_service.BatchProcessRequest(\n",
    "    name=name,\n",
    "    input_configs=input_configs,\n",
    "    output_config=output_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the batch (asynchronous) API operation \n",
    "operation = client.batch_process_documents(request)\n",
    "# Wait for the operation to finish\n",
    "operation.result(timeout=timeout)\n",
    "print (\"Batch process  completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch list of output files\n",
    "match = re.match(r\"gs://([^/]+)/(.+)\", destination_uri)\n",
    "output_bucket = match.group(1)\n",
    "prefix = match.group(2)\n",
    "bucket = storage_client.get_bucket(output_bucket)\n",
    "blob_list = list(bucket.list_blobs(prefix=prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detected text from asynchronous output JSON files\n",
    "for i, blob in enumerate(blob_list):\n",
    "    # If JSON file, download the contents of this blob as a bytes object.\n",
    "    if \".json\" in blob.name:\n",
    "        blob_as_bytes = blob.download_as_bytes()\n",
    "        document = documentai.types.Document.from_json(blob_as_bytes)\n",
    "        print(f\"Fetched file {i + 1}:{blob.name}\")\n",
    "        # print the text data output from the processor\n",
    "        print(f\"Text Data:\\n {document.text}\")\n",
    "    else:\n",
    "        print(f\"Skipping non-supported file type {blob.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display entity data from asynchronous output JSON files\n",
    "for i, blob in enumerate(blob_list):\n",
    "    # If JSON file, download the contents of this blob as a bytes object.\n",
    "    if \".json\" in blob.name:\n",
    "        blob_as_bytes = blob.download_as_bytes()\n",
    "        document = documentai.types.Document.from_json(blob_as_bytes)\n",
    "        print(f\"Fetched file {i + 1}:{blob.name}\")\n",
    "        # print the entity data output from the processor\n",
    "        if 'entities' in dir(document):\n",
    "            entities=document.entities\n",
    "            table = PrettyTable(['Type', 'Value', 'Confidence'])\n",
    "            entities_found = 0\n",
    "            for entity in entities:\n",
    "               entity_type = entity.type_\n",
    "               value = entity.mention_text\n",
    "               confidence = round(entity.confidence,4)\n",
    "               table.add_row([entity_type, value, confidence])\n",
    "            print(table)   \n",
    "        else:\n",
    "            print('No entity data returned by the Document AI processor for file'+blob.name)\n",
    "    else:\n",
    "        print(f\"Skipping non-supported file type {blob.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LendingAI Bouding Boxes v3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "common-cpu.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
