{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Call Gemini using the OpenAI Library\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/chat-completions/intro_chat_completions_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fchat-completions%2Fintro_chat_completions_api.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/chat-completions/intro_chat_completions_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/chat-completions/intro_chat_completions_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84f0f73a0f76"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Eric Dong](https://github.com/gericdong)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Developers already working with OpenAI's libraries can easily tap into the power of Gemini by leveraging the Gemini Chat Completions API. The Gemini Chat Completions API offers a streamlined way to experiment with and incorporate Gemini's capabilities into your existing AI applications. Learn more about [calling Gemini by using the OpenAI library](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/call-gemini-using-openai-library).\n",
    "\n",
    "In this tutorial, you learn how to call Gemini using the OpenAI library. You will complete the following tasks:\n",
    "\n",
    "- Configure OpenAI SDK for the Gemini Chat Completions API\n",
    "- Send a chat completions request\n",
    "- Stream chat completions response\n",
    "- Send a multimodal request\n",
    "- Send a function calling request\n",
    "- Send a function calling request with the `tool_choice` parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XRvKdaPDTznN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. The restart might take a minute or longer. After it's restarted, continue to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-01-20ea2812d961\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-east4\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "## Chat Completions API Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHwJCyNF6u0O"
   },
   "source": [
    "### Configure OpenAI SDK for the Gemini Chat Completions API\n",
    "\n",
    "\n",
    "#### Import libraries\n",
    "\n",
    "The `google-auth` library is used to programmatically get Google credentials. Colab already has this library pre-installed. If you don't have it in your environment, use the following command to install it.\n",
    "\n",
    "`!pip install google-auth requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kolJkBLdHaw0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.auth import default, transport\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0K6VSJRHhH2"
   },
   "source": [
    "#### Authentication\n",
    "\n",
    "You can request an access token from the default credentials for the current environment. Note that the access token lives for 1 hour by default (https://cloud.google.com/docs/authentication/token-types#at-lifetime); after expiration, it must be refreshed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i0qceuiQEPHv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials, _ = default()\n",
    "auth_request = transport.requests.Request()\n",
    "credentials.refresh(auth_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q04wJmA0HT6X"
   },
   "source": [
    "Then configure the OpenAI SDK to point to the Gemini Chat Completions API endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c-MRhsnlj6iw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=f\"https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
    "    api_key=credentials.token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGokrtdiIHrX"
   },
   "source": [
    "#### Gemini models\n",
    "\n",
    "You can experiment with [various supported Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/call-gemini-using-openai-library#supported_models). If you are not sure which model to use, then try `gemini-1.5-flash`. `gemini-1.5-flash` is optimized for multimodal use cases where speed and cost are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "r7OhyH46H2H5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"google/gemini-1.5-flash\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiWrF7U4Q5-E"
   },
   "source": [
    "### [Example] Send a chat completions request\n",
    "\n",
    "The Chat Completions API takes a list of messages as input and returns a generated message as output. Although the message format is designed to make multi-turn conversations easy, it's just as useful for single-turn tasks without any conversation.\n",
    "\n",
    "In this example, you use the Chat Completions API to send a request to the Gemini model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JQTWLCzoHyUA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID, messages=[{\"role\": \"user\", \"content\": \"Why is the sky blue?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLNZGyOVOr1C"
   },
   "source": [
    "An example Chat Completions API response looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DdfWBfggOvtf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='2024-10-18|19:12:36.627517-07|3.100.200.140|1259231030', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's the breakdown:\\n\\n* **Sunlight is made up of all colors of the rainbow.**  When sunlight enters the Earth's atmosphere, it interacts with the tiny gas molecules (mostly nitrogen and oxygen).\\n* **Shorter wavelengths scatter more.**  Blue light has a shorter wavelength than other colors of the rainbow (like red).  When sunlight hits these tiny molecules, blue light is scattered in all directions much more strongly than other colors.\\n* **Scattered light reaches our eyes.**  This scattered blue light is what we see as the blue sky.\\n\\n**Why is the sky red at sunset and sunrise?**\\n\\n* **Longer path through atmosphere.**  At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes. \\n* **Blue light is scattered away.**  This longer path means more blue light is scattered away, leaving the longer wavelengths (red and orange) to reach our eyes.\\n\\nLet me know if you have any more questions! \\n\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729303956, model='google/gemini-1.5-flash', object='chat.completion', service_tier=None, system_fingerprint='', usage=CompletionUsage(completion_tokens=220, prompt_tokens=6, total_tokens=226, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ipbzw5FmO5zX"
   },
   "source": [
    "The generated content can be extracted with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LxpdxYCxH51u",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's the breakdown:\\n\\n* **Sunlight is made up of all colors of the rainbow.**  When sunlight enters the Earth's atmosphere, it interacts with the tiny gas molecules (mostly nitrogen and oxygen).\\n* **Shorter wavelengths scatter more.**  Blue light has a shorter wavelength than other colors of the rainbow (like red).  When sunlight hits these tiny molecules, blue light is scattered in all directions much more strongly than other colors.\\n* **Scattered light reaches our eyes.**  This scattered blue light is what we see as the blue sky.\\n\\n**Why is the sky red at sunset and sunrise?**\\n\\n* **Longer path through atmosphere.**  At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes. \\n* **Blue light is scattered away.**  This longer path means more blue light is scattered away, leaving the longer wavelengths (red and orange) to reach our eyes.\\n\\nLet me know if you have any more questions! \\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSIVXw7bMr4F"
   },
   "source": [
    "You can use `Markdown` to display the formatted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zOwEvNkCMiMF",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's the breakdown:\n",
       "\n",
       "* **Sunlight is made up of all colors of the rainbow.**  When sunlight enters the Earth's atmosphere, it interacts with the tiny gas molecules (mostly nitrogen and oxygen).\n",
       "* **Shorter wavelengths scatter more.**  Blue light has a shorter wavelength than other colors of the rainbow (like red).  When sunlight hits these tiny molecules, blue light is scattered in all directions much more strongly than other colors.\n",
       "* **Scattered light reaches our eyes.**  This scattered blue light is what we see as the blue sky.\n",
       "\n",
       "**Why is the sky red at sunset and sunrise?**\n",
       "\n",
       "* **Longer path through atmosphere.**  At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes. \n",
       "* **Blue light is scattered away.**  This longer path means more blue light is scattered away, leaving the longer wavelengths (red and orange) to reach our eyes.\n",
       "\n",
       "Let me know if you have any more questions! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zOwEvNkCMiMF",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please like share & subscribe to Techcps https://www.youtube.com/@techcps\n"
     ]
    }
   ],
   "source": [
    "# Please like share & subscribe to Techcps\n",
    "\n",
    "print(\"Please like share & subscribe to Techcps https://www.youtube.com/@techcps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpHc6sC6PIcI"
   },
   "source": [
    "### [Example] Stream chat completions response\n",
    "\n",
    "By default, the model returns a response after completing the entire generation process. You can also stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3hO8yLqnJEgh",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      " sky is blue because of a phenomenon called **Rayleigh scattering**. Here's\n",
      " the breakdown:\n",
      "\n",
      "* **Sunlight is made up of all colors of the rainbow\n",
      ".**  These colors are different wavelengths of light.\n",
      "* **The atmosphere is filled with tiny particles.** These particles are much smaller than the wavelengths of visible light\n",
      ".\n",
      "* **When sunlight hits these particles, it gets scattered in all directions.**  This is called scattering.\n",
      "* **Shorter wavelengths of light (blue\n",
      " and violet) are scattered more than longer wavelengths (red and orange).** This is because shorter wavelengths interact more strongly with the tiny particles in the air.\n",
      "* **Our eyes are more sensitive to blue light than violet light.** So,\n",
      " we see the sky as a beautiful blue color.\n",
      "\n",
      "**Here's a simple analogy:**\n",
      "\n",
      "Imagine shining a flashlight through a glass of milk. The milk scatters the light, and it appears blue. The atmosphere works in a similar way,\n",
      " scattering blue light more than other colors.\n",
      "\n",
      "**Fun fact:**\n",
      "\n",
      "The sky appears red at sunset and sunrise because the sunlight has to travel through more of the atmosphere. This means more blue light is scattered away, leaving the longer wavelengths (red and orange) to reach our eyes. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Why is the sky blue?\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqNdZLK8VLaf"
   },
   "source": [
    "### [Example] Send a multimodal request\n",
    "You can send a multimodal prompt in a request to Gemini and get a text output.\n",
    "\n",
    "In this example, you ask the model to create a blog post for [this image](https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png) stored in a Cloud Storage bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KOIu1Me-PQ6e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Meal Prep Made Easy: Teriyaki Chicken & Veggies\n",
      "\n",
      "Forget the takeout! This Teriyaki Chicken & Veggie meal prep is the perfect solution for busy weeknights. Packed with protein, veggies, and healthy carbs, it's both delicious and nutritious. \n",
      "\n",
      "**Here's what you need:**\n",
      "\n",
      "* **Chicken:** Marinate your chicken in teriyaki sauce and cook it to perfection. \n",
      "* **Veggies:** Broccoli and peppers add a burst of freshness and color. \n",
      "* **Rice:** Brown rice is a great source of fiber and will keep you feeling full. \n",
      "\n",
      "**Here's what you do:**\n",
      "\n",
      "1. Divide your cooked chicken, veggies, and rice into individual containers.\n",
      "2. Store in the refrigerator for up to 3 days.\n",
      "3. Grab and go! Reheat in the microwave or on the stovetop. \n",
      "\n",
      "**Pro Tip:** Add a sprinkle of sesame seeds for extra flavor and crunch.\n",
      "\n",
      "With this easy meal prep, you'll have healthy and flavorful dinners ready to go all week long!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Write a short, engaging blog post based on this picture.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"gs://cloud-samples-data/generative-ai/image/meal.png\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPJot5D_dE6G"
   },
   "source": [
    "### [Example] Send a function calling request\n",
    "\n",
    "You can use the Chat Completions API for function calling with the Gemini models. The `tools` parameter in the API is used to provide function specifications. This is to enable models to generate function arguments which adhere to the provided specifications.\n",
    "\n",
    "In this example, you create function specifications to interface with a hypothetical weather API, then pass these function specifications to the Chat Completions API to generate function arguments that adhere to the specification.\n",
    "\n",
    "**Note** that in this example, the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "arshz2C4W_ck",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='get_current_weather', function=Function(arguments='{\"location\":\"Boston\"}', name='get_current_weather'), type='function')]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\",\n",
    "    }\n",
    ")\n",
    "messages.append({\"role\": \"user\", \"content\": \"What is the weather in Boston?\"})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(print(response.choices[0].message.tool_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B82QRs9Oc1HL"
   },
   "source": [
    "### [Example] Send a function calling request with the `tool_choice` parameter\n",
    "\n",
    "Using the `tools` parameter, if the functions parameter is provided then by default the model will decide when it is appropriate to use one of the functions.\n",
    "\n",
    "By default, `tool_choice` is set to `auto`. This lets the model decide whether to call functions and, if so, which functions to call. To disable function calling and force the model to only generate a user-facing message, you can set `tool_choice` to `none`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GoEv7CKNXZu1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='get_current_weather', function=Function(arguments='{\"location\":\"Boston\"}', name='get_current_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = []\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\",\n",
    "    }\n",
    ")\n",
    "messages.append({\"role\": \"user\", \"content\": \"What is the weather in Boston?\"})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_chat_completions_api.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
