{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Getting Started with Grounding with Gemini in Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgrounding%2Fintro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49e1e41cea0d"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Holt Skinner](https://github.com/holtskinner), [Kristopher Overholt](https://github.com/koverholt) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**_NOTE_**: This notebook has been tested in the following environment:\n",
    "\n",
    "* Python version = 3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Grounding in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you use generative text models to generate content grounded in your own documents and data. This capability lets the model access information at runtime that goes beyond its training data. By grounding model responses in Google Search results or data stores within [Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction), LLMs that are grounded in data can produce more accurate, up-to-date, and relevant responses.\n",
    "\n",
    "Grounding provides the following benefits:\n",
    "\n",
    "- Reduces model hallucinations (instances where the model generates content that isn't factual)\n",
    "- Anchors model responses to specific information, documents, and data sources\n",
    "- Enhances the trustworthiness, accuracy, and applicability of the generated content\n",
    "\n",
    "In the context of grounding in Vertex AI, you can configure two different sources of grounding:\n",
    "\n",
    "1. Google Search results for data that is publicly available and indexed\n",
    "2. [Data stores in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest), which can include your own data in the form of website data, unstructured data, or structured data\n",
    "\n",
    "### Allowlisting\n",
    "\n",
    "Some of the features in this sample notebook require access to certain features via an allowlist. [Grounding with Vertex AI Search](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) is available in Public Preview, whereas Grounding with Google Search results is generally available.\n",
    "\n",
    "If you use this service in a production application, you will also need to [use a Google Search entry point](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to:\n",
    "\n",
    "- Generate LLM text and chat model responses grounded in Google Search results\n",
    "- Compare the results of ungrounded LLM responses with grounded LLM responses\n",
    "- Create and use a data store in Vertex AI Search to ground responses in custom documents and data\n",
    "- Generate LLM text and chat model responses grounded in Vertex AI Search results\n",
    "\n",
    "This tutorial uses the following Google Cloud AI services and resources:\n",
    "\n",
    "- Vertex AI\n",
    "- Vertex AI Search and Conversation\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Configuring the LLM and prompt for various examples\n",
    "- Sending example prompts to generative text and chat models in Vertex AI\n",
    "- Setting up a data store in Vertex AI Search with your own data\n",
    "- Sending example prompts with various levels of grounding (no grounding, web grounding, data store grounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "1. Enable the [Vertex AI and Vertex AI Agent Builder APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,discoveryengine.googleapis.com).\n",
    "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2b4ef9b72d43",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "Restart the kernel after installing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f200f10a1da3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb05997a457d"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "If you are running this notebook on Google Colab, you will need to authenticate your environment. To do this, run the new cell below. This step is not required if you are using Vertex AI Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "603adbbf0532",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oM1iC_MfAts1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-04-bde50cd42a87\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "init_aip:mbsdk,all",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PyQmSRbKA8r-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from vertexai.generative_models import (\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    grounding,\n",
    ")\n",
    "from vertexai.preview.generative_models import grounding as preview_grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cf2dd17690"
   },
   "source": [
    "Initialize the Gemini model from Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "652a8969dd5a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff453ac772d4"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3dce100cab74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_grounding_response(response: GenerationResponse):\n",
    "    \"\"\"Prints Gemini response with grounding citations.\"\"\"\n",
    "    grounding_metadata = response.candidates[0].grounding_metadata\n",
    "\n",
    "    # Citation indices are in byte units\n",
    "    ENCODING = \"utf-8\"\n",
    "    text_bytes = response.text.encode(ENCODING)\n",
    "\n",
    "    prev_index = 0\n",
    "    markdown_text = \"\"\n",
    "\n",
    "    for grounding_support in grounding_metadata.grounding_supports:\n",
    "        text_segment = text_bytes[\n",
    "            prev_index : grounding_support.segment.end_index\n",
    "        ].decode(ENCODING)\n",
    "\n",
    "        footnotes_text = \"\"\n",
    "        for grounding_chunk_index in grounding_support.grounding_chunk_indices:\n",
    "            footnotes_text += f\"[{grounding_chunk_index + 1}]\"\n",
    "\n",
    "        markdown_text += f\"{text_segment} {footnotes_text}\\n\"\n",
    "        prev_index = grounding_support.segment.end_index\n",
    "\n",
    "    if prev_index < len(text_bytes):\n",
    "        markdown_text += str(text_bytes[prev_index:], encoding=ENCODING)\n",
    "\n",
    "    markdown_text += \"\\n----\\n## Grounding Sources\\n\"\n",
    "\n",
    "    if grounding_metadata.web_search_queries:\n",
    "        markdown_text += (\n",
    "            f\"\\n**Web Search Queries:** {grounding_metadata.web_search_queries}\\n\"\n",
    "        )\n",
    "        if grounding_metadata.search_entry_point:\n",
    "            markdown_text += f\"\\n**Search Entry Point:**\\n {grounding_metadata.search_entry_point.rendered_content}\\n\"\n",
    "    elif grounding_metadata.retrieval_queries:\n",
    "        markdown_text += (\n",
    "            f\"\\n**Retrieval Queries:** {grounding_metadata.retrieval_queries}\\n\"\n",
    "        )\n",
    "\n",
    "    markdown_text += \"### Grounding Chunks\\n\"\n",
    "\n",
    "    for index, grounding_chunk in enumerate(\n",
    "        grounding_metadata.grounding_chunks, start=1\n",
    "    ):\n",
    "        context = grounding_chunk.web or grounding_chunk.retrieved_context\n",
    "        if not context:\n",
    "            print(f\"Skipping Grounding Chunk {grounding_chunk}\")\n",
    "            continue\n",
    "\n",
    "        markdown_text += f\"{index}. [{context.title}]({context.uri})\\n\"\n",
    "\n",
    "    display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e336da7161af"
   },
   "source": [
    "## Example: Grounding with Google Search results\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search. You'll ask a question about a recent hardware release from the Google Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6a28ca4abb52",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT = \"You are an expert in astronomy. When is the next solar eclipse in the US?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25955ce5d263"
   },
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a2e348ff93e6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I can't give you the date of the next solar eclipse in the US.  I can generate human-like text in response to a wide range of prompts and questions, but my knowledge about upcoming astronomical events is limited. \n",
       "\n",
       "**To find the date of the next solar eclipse, I recommend checking these resources:**\n",
       "\n",
       "* **NASA Eclipse Website:** This website has a comprehensive list of upcoming eclipses, including dates, times, and locations.\n",
       "* **Time and Date Website:** This website provides detailed information about eclipses, including interactive maps and visibility information.\n",
       "* **Astronomy Magazines and Websites:** Publications like Astronomy Magazine or Sky & Telescope regularly publish articles about upcoming astronomical events, including eclipses. \n",
       "\n",
       "I hope this helps! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = model.generate_content(PROMPT)\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d7cb7cceb99"
   },
   "source": [
    "### Text generation grounded in Google Search results\n",
    "\n",
    "Now you can add the `tools` keyword arg with a `grounding` tool of `grounding.GoogleSearchRetrieval()` to instruct the LLM to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
    "\n",
    "The search queries and [Search Entry Point](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points) are available for each `Candidate` in the response. The helper function `print_grounding_response()` prints the response text with citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1d9fb83b0ab9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The next total solar eclipse in the US will be on August 23, 2044. [1][2]\n",
       " This eclipse will be visible in Greenland, Canada, and parts of the United States, specifically Montana, North Dakota, and South Dakota. [1]\n",
       " \n",
       "\n",
       "While the US will experience a partial solar eclipse on March 29, 2025, in the far northeastern reaches, the next total solar eclipse visible from the contiguous US won't happen until 2044. [3]\n",
       " After that, the next total solar eclipse viewable from the US will be in 2045. [1]\n",
       "\n",
       "\n",
       "Total solar eclipses are a rare and spectacular sight. During a total solar eclipse, the Moon passes between the Sun and Earth, completely blocking the Sun's light. This allows observers in the path of totality to see the Sun's corona, which is its outer atmosphere. [2]\n",
       " \n",
       "\n",
       "Although there are solar eclipses every year, they are only visible from a small area on Earth.  The US is fortunate to have eight total solar eclipses predicted to occur in the 21st century. This means that, on average, a total solar eclipse is visible from some part of North America approximately every twelve years. [1]\n",
       " \n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "\n",
       "**Web Search Queries:** ['next solar eclipse in the US']\n",
       "\n",
       "**Search Entry Point:**\n",
       " <style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AYygrcS6TAJerbiWUDqTA2Sl47kC1xgD5D4oT-DalhiqtUxCNtrMD1uMoGPH_VMbwfnfL-Rusv9nB1CN8xH6jOEThRFOXfsS0RwmqkYN2OBjAAOEgDibHjYLARDQ_84HlYsG3qvAyxYpFNKPNRzsxR1HMjlOr0gDbFK1Pdn2JveHt3aknelRK85BBvOAefvZNN_HJgciXIIhmnGlxBhP1NqRJKU=\">next solar eclipse in the US</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n",
       "### Grounding Chunks\n",
       "1. [cbsnews.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AYygrcQ8b1hLAix8HDnjKrDziAZP13fxn4odRMuPy1glEzwZQNAqbM7h-geXrXZoqL9BRmePA5jkLjfD7qTyAK_iS0NM2hvnaAIdCxs0NsPQxkL6VnZQwD7I8BUKnOCEUD5vJBJ8KXsSr00j8W69_cYsSBJCoPLMYES4WHoqo7w=)\n",
       "2. [nasa.gov](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AYygrcQoVi-TSgWzKb21m1RTpeXrNoKJybwS41Ub3MTC5yb9QggpkY4o_duxDF_nv7khBAR9iaesX0YFyY7dytUTtyEFH96E8kYOYZjhW-npzkTKWFW9TTu-hzDLmOqad7rCJ50uXsIxRg5Mb80DTel23pF7WSa3pKLVYnScFQ==)\n",
       "3. [space.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AYygrcTx0GmwrUYer8WOhULOpF4-2KwoT5RHOxpk5vWZYzCBgHf7b2RghQ-wVqF5Jc-XrhHOkHzc5hAYkPESafECOdTbXHGwviiHEqdquiNkGfAENdA5haIWWH3GFf2YPeyjj7uMOWpJVK4nbDU0lTe03yMkwA==)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n",
    "\n",
    "response = model.generate_content(PROMPT, tools=[tool])\n",
    "\n",
    "print_grounding_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d3920bb2ac0"
   },
   "source": [
    "Note that the response without grounding only has limited information from the LLM about solar eclipses. Whereas the response that was grounded in web search results contains the most up to date information from web search results that are returned as part of the LLM with grounding request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77f0800f8762"
   },
   "source": [
    "## Example: Grounding with custom documents and data\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the [results of a data store in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest). You'll ask a question about a GoogleSQL query to create an [object table in BigQuery](https://cloud.google.com/bigquery/docs/object-table-introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b308548c68b"
   },
   "source": [
    "### Creating a data store in Vertex AI Search\n",
    "\n",
    "In this example, you'll use a website-based data store that contains content from the Google Cloud website, including documentation.\n",
    "\n",
    "Refer to __Task 4__ and __Task 5__ in the lab instruction manual to perform the steps advised below. Once the data store has been created, make note of the ID to input in the cells below.\n",
    "\n",
    "Follow the tutorial steps in the Vertex AI Search documentation to:\n",
    "\n",
    "1. [Create a data store with website data](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_data_store) that uses the URL pattern `cloud.google.com/*` in the **Sites to include** field.\n",
    "2. [Create a search app](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app) that is attached to that data store. You should also enable the **Enterprise edition features** so that you can search indexed records within the data store.\n",
    "\n",
    "Note: The data store must be in the same project that you are using for Gemini.\n",
    "\n",
    "__Once you've created a data store, obtain the Data Store ID and input it below.__\n",
    "\n",
    "Note: You will need to wait for data ingestion to finish before using a data store with grounding. For more information, see [create a data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcd767476241"
   },
   "outputs": [],
   "source": [
    "DATA_STORE_PROJECT_ID = PROJECT_ID  # @param {type:\"string\"}\n",
    "DATA_STORE_REGION = \"global\"  # @param {type:\"string\"}\n",
    "# Replace this with your data store ID from Vertex AI Search\n",
    "DATA_STORE_ID = \"techcps_1733829237636\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccc156676e0a"
   },
   "source": [
    "Now you can ask a question about object tables in BigQuery and when to use them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c1e1b1743bd"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"When should I use an object table in BigQuery? And how does it store data?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f365681544bb"
   },
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "299818ae71e9"
   },
   "outputs": [],
   "source": [
    "response = model.generate_content(PROMPT)\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "073f2ec42ff6"
   },
   "source": [
    "### Text generation grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `tools` keyword arg with a grounding tool of `grounding.VertexAISearch()` to instruct the LLM to first perform a search within your custom data store, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4c5d53a37b4"
   },
   "outputs": [],
   "source": [
    "tool = Tool.from_retrieval(\n",
    "    preview_grounding.Retrieval(\n",
    "        preview_grounding.VertexAISearch(\n",
    "            datastore=DATA_STORE_ID,\n",
    "            project=DATA_STORE_PROJECT_ID,\n",
    "            location=DATA_STORE_REGION,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "response = model.generate_content(PROMPT, tools=[tool])\n",
    "print_grounding_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3f985c704cd"
   },
   "source": [
    "Note that the response without grounding only has limited information from the LLM about object tables in BigQuery that might not be accurate. Whereas the response that was grounded in Vertex AI Search results contains the most up to date information from the Google Cloud documentation about BigQuery, along with citations of the information.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Important notes:</b><br>\n",
    "<br>\n",
    "<b>If you get an error when running the previous cell:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;In order for this sample notebook to work with data store in Vertex AI Search,<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;you'll need to create a <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_data_store\">data store</a> <b>and</b> a <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app\">search app</a> associated with it in Vertex AI Search.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;If you only create a data store, the previous request will return errors when making queries against the data store.\n",
    "<br><br>\n",
    "<b>If you get an empty response when running the previous cell:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;You will need to wait for data ingestion to finish before using a data store with grounding.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;For more information, see <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es\">create a data store</a>.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54562717e2a4"
   },
   "source": [
    "## Example: Grounded chat responses\n",
    "\n",
    "You can also use grounding when working with chat models in Vertex AI. In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search and a data store in Vertex AI Search.\n",
    "\n",
    "You'll ask a question about Vertex AI and a follow up question about managed datasets in Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "490cf1ed3399"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What are managed datasets in Vertex AI?\"\n",
    "PROMPT_FOLLOWUP = \"What types of data can I use?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4e8fa97a38e"
   },
   "source": [
    "### Chat session without grounding\n",
    "\n",
    "Start a chat session and send messages to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f64690348d29"
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()\n",
    "\n",
    "response = chat.send_message(PROMPT)\n",
    "display(Markdown(response.text))\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b59783e4f1ce"
   },
   "source": [
    "### Chat session grounded in Google Search results\n",
    "\n",
    "Now you can add the `tools` keyword arg with a grounding tool of `grounding.GoogleSearchRetrieval()` to instruct the chat model to first perform a Google Search with the prompt, then construct an answer based on the web search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58edb2bd860f"
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()\n",
    "tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n",
    "\n",
    "response = chat.send_message(PROMPT, tools=[tool])\n",
    "print_grounding_response(response)\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP, tools=[tool])\n",
    "print_grounding_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87be7f661f14"
   },
   "source": [
    "### Chat session grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `tools` keyword arg with a grounding tool of `grounding.VertexAISearch()` to instruct the chat model to first perform a search within your custom data store, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a824202a8f0"
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()\n",
    "tool = Tool.from_retrieval(\n",
    "    preview_grounding.Retrieval(\n",
    "        preview_grounding.VertexAISearch(\n",
    "            datastore=DATA_STORE_ID,\n",
    "            project=DATA_STORE_PROJECT_ID,\n",
    "            location=DATA_STORE_REGION,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "response = chat.send_message(PROMPT, tools=[tool])\n",
    "print_grounding_response(response)\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP, tools=[tool])\n",
    "print_grounding_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To avoid incurring charges to your Google Cloud account for the resources used in this notebook, follow these steps:\n",
    "\n",
    "1. To avoid unnecessary Google Cloud charges, use the [Google Cloud console](https://console.cloud.google.com/) to delete your project if you do not need it. Learn more in the Google Cloud documentation for [managing and deleting your project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n",
    "1. If you used an existing Google Cloud project, delete the resources you created to avoid incurring charges to your account. For more information, refer to the documentation to [Delete data from a data store in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/delete-datastores), then delete your data store.\n",
    "1. Disable the [Vertex AI Search and Conversation API](https://console.cloud.google.com/apis/api/discoveryengine.googleapis.com) and [Vertex AI API](https://console.cloud.google.com/apis/api/aiplatform.googleapis.com) in the Google Cloud Console."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro-grounding-gemini.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
