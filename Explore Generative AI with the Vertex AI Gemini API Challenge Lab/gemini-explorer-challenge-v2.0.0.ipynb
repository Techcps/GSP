{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc61ef2",
   "metadata": {},
   "source": [
    "### Getting Started "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5040b",
   "metadata": {},
   "source": [
    "#### Install Google Gen AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0cb94a-444f-4360-9196-395da2f58a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a8346",
   "metadata": {},
   "source": [
    "#### Restart runtime\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58aad280-7db1-4e39-886b-336d7e5791d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernel after libraries are loaded\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f5a9c",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45472ded-bc1f-47a5-9782-fb8fb8538f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"!(gcloud config get-value core/project)\"  # @param {type:\"string\"}\n",
    "\n",
    "region_output = !gcloud compute project-info describe --format=\"value(commonInstanceMetadata.items[google-compute-default-region])\"\n",
    "LOCATION = region_output[0].strip()\n",
    "\n",
    "# Get project ID properly\n",
    "project_output = !gcloud config get-value core/project\n",
    "PROJECT_ID = project_output[0].strip()\n",
    "\n",
    "print(\"LOCATION:\", LOCATION)\n",
    "print(\"PROJECT_ID:\", PROJECT_ID)\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Create the API client\n",
    "from google import genai\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a41c22f-ff93-43b5-8d37-15014c43bd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please like share & subscribe to Techcps https://www.youtube.com/@techcps\n"
     ]
    }
   ],
   "source": [
    "# Please like share & subscribe to Techcps\n",
    "# YouTube https://www.youtube.com/@techcps\n",
    "\n",
    "print(\"Please like share & subscribe to Techcps https://www.youtube.com/@techcps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d907146",
   "metadata": {},
   "source": [
    "#### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c672ce5-01ee-4884-a76f-c069d06c412a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.genai.types import (\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    Tool,\n",
    "    Part\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc901e8a",
   "metadata": {},
   "source": [
    "### Task 3. Create a function call using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb0e9207-2646-4378-9350-cef083822807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.1\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "# Load Gemini 2.0 Flash 001 Model\n",
    "model_id = (\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d349748-4a56-4759-98d7-e918b476c317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.2\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Get the current weather in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Location\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280aa0f9-ef27-4664-b9f6-ed6847d8f76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.3\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "weather_tool = Tool(\n",
    "    function_declarations=[get_current_weather_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b41dfd-5d43-4c21-8992-c76ed319af66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-5.061081278004817e-06,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            function_call=FunctionCall(\n",
       "              args=<... Max depth ...>,\n",
       "              name=<... Max depth ...>\n",
       "            )\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 6, 27, 4, 43, 59, 243237, tzinfo=TzInfo(UTC)),\n",
       "  model_version='gemini-2.0-flash-001',\n",
       "  response_id='jyFeaKXsDq6KjNsPyMz24Q0',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=7,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=7\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=25,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=25\n",
       "      ),\n",
       "    ],\n",
       "    total_token_count=32,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3.4\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "prompt = \"What is the weather like in Boston?\"\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[weather_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de586d1d",
   "metadata": {},
   "source": [
    "### Task 4. Describe video contents using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8033df-507a-4fc8-b14c-f015be9f66af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the following cell to import required libraries \n",
    "from google.genai.types import (\n",
    "    GenerationConfig,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75434b8d-e7d0-4241-9cab-fa735a617b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 4.1\n",
    "# Load the correct Gemini model use the following documentation to assist:\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview#supported-use-cases\n",
    "# Load Gemini 2.0 Flash 001 Model\n",
    "multimodal_model = (\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b6f262-1956-4c3e-a0ab-39b412d19ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17aae9ba-edcb-4c63-af88-26380dfd5170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Prompt--------\n",
      "\n",
      "What is shown in this video?\n",
      "Where should I go to see it?\n",
      "What are the top 5 places in the world that look like this?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\" controls  width=\"600\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      "Okay, here is some information regarding the image in the video:\n",
      "\n",
      "**What is shown in the video?**\n",
      "\n",
      "The video shows an aerial view of Antalya, Turkey, specifically the old harbor or marina (Kaleiçi Marina). It features a stone breakwater with a lighthouse, boats docked in the harbor, the sea, and cliffs with buildings along the coastline.\n",
      "\n",
      "**Where should I go to see it?**\n",
      "\n",
      "You would need to travel to Antalya, Turkey, and visit the Kaleiçi Marina, which is the old harbor area of the city.\n",
      "\n",
      "**What are the top 5 places in the world that look like this?**\n",
      "\n",
      "Based on the features shown (coastal cliffs, turquoise water, a historic harbor, and a Mediterranean vibe), here are five places with a similar aesthetic:\n",
      "\n",
      "1.  **Dubrovnik, Croatia:** Known for its walled old town, coastal setting, and beautiful turquoise waters.\n",
      "2.  **Cinque Terre, Italy:** A string of colorful villages perched on the Italian Riviera coastline.\n",
      "3.  **Santorini, Greece:** Famous for its white-washed buildings, volcanic landscape, and the Aegean Sea.\n",
      "4.  **Valletta, Malta:** A historic walled city with a harbor, coastal views, and a Mediterranean climate.\n",
      "5.  **Positano, Italy:** Picturesque village on the Amalfi Coast, known for its dramatic cliffs, colorful buildings, and beautiful views.\n",
      "\n",
      "I hope this helps!"
     ]
    }
   ],
   "source": [
    "# Task 4.2 Generate a video description\n",
    "# In this cell, update the prompt to ask Gemini to describe the video URL referenced.\n",
    "# You can use the documentation at the following link to assist.\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference#generate-content-from-video\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests-text-stream-response\n",
    "# Video URI: gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\n",
    "\n",
    "prompt = \"\"\"\n",
    "What is shown in this video?\n",
    "Where should I go to see it?\n",
    "What are the top 5 places in the world that look like this?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    file_uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = client.models.generate_content_stream(\n",
    "    model=multimodal_model,\n",
    "    contents=contents\n",
    ")\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b2ebd-b803-4d9f-8b9c-fd998caded66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
